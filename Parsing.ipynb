{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.parsers import parse_reporting_info, parse_closed_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTING_DATA_FOLDER = 'parsed_data/bank_reporting/'\n",
    "CLOSED_BANKS_DATA_FOLDER = 'parsed_data/closed_banks/'\n",
    "\n",
    "# Список из ID страничек и соответствующие им названия переменных. \n",
    "ID_list = ['10','30','25','20','40','50','60','500','1000','1100','1200','1300','1400','1500','1550',\\\n",
    "           '1600','1700','1800','200','260','300','360','120','70','110','130','140','160','400','401']\n",
    "\n",
    "ID_names_list = ['na','ni','c_123','c_134','cp','LLPGL','dep_f','dep_b','ROA','ROE','LLP','IR','LCP','fr_na',\\\n",
    "                 'fr','H1','H2','H3','c_f','LLP_c_f','c_b','LLP_c_b','ibl','sec_tot','liquid','sec','bond','oth_cap',\\\n",
    "                 'retail','retail_fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bank reporting info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируем лист из дат, которые необходимо пробежать.\n",
    "# февраль 17 - март 08  (2017-02-01 до  2008-03-01)\n",
    "years = [str(item) for item in range(2010,2018)]\n",
    "months = [str(item) for item in range(1,13)]\n",
    "months2 = [ ]\n",
    "for item in months:\n",
    "    if len(item)==1:\n",
    "        item = '0'+item\n",
    "    months2.append(item)\n",
    "dats = [ ]\n",
    "for item in years:\n",
    "    for jtem in months2:\n",
    "        dats.append(item + '-' + jtem + '-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_reporting_info(ID_list, dats, path=REPORTING_DATA_FOLDER)\n",
    "parse_closed_banks(path=CLOSED_BANKS_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала неплохо было бы выявить список из уникальных банков! \n",
    "\n",
    "# Функция, которая обхелиняет два лоиста по уникалтным названиям \n",
    "# Она делает пересечение двух множеств \n",
    "def union(a, b):\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "def Uniq_banks(frames):\n",
    "    uniq_banks = list(frames[0]['Лицензия_банк'])\n",
    "    for item in ID_list:\n",
    "        uniq_banks = union(uniq_banks,item)\n",
    "    return(uniq_banks)\n",
    "\n",
    "# Сохраним ко всему прочему информацию о том какие банки уникальны.\n",
    "uniq_banks = Uniq_banks(frames)\n",
    "un_banks = pd.DataFrame()\n",
    "un_banks['Уникальные банки'] = uniq_banks\n",
    "\n",
    "# Делаем список из датафреймов, которые мы подгружаем из папки. Соединим все показатели в один датафрейм\n",
    "frames = [pd.read_csv(REPORTING_DATA_FOLDER + strtem +'.csv', header=0, sep=',', encoding=\"cp1251\") \n",
    "          for strtem in ID_list]\n",
    "df_all = frames[0].set_index(['лицензия', 'дата'])\n",
    "    \n",
    "i = 1\n",
    "while i <= len(frames):\n",
    "    df_tmp = pd.DataFrame(frames[i])\n",
    "    df_all = df_all.join(df_tmp.set_index(['лицензия', 'дата']), how = 'outer')\n",
    "    df_all.drop_duplicates(keep = 'first', inplace =True)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для выделения номера лицензии из строки\n",
    "def get_license(string):\n",
    "    license = string.split('№ ')[1].split(',')[0]\n",
    "    return license\n",
    "\n",
    "bank_frame['лицензия'] = bank_frame['Лицензия_банк'].apply(get_license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(REPORTING_DATA_FOLDER + 'reporting_all.csv', sep=',',header=True,index=True)\n",
    "un_banks.to_csv(REPORTING_DATA_FOLDER + 'unique_banks.csv',sep='\\t',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Closed banks info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_closed_banks(path=CLOSED_BANKS_DATA_FOLDER, mainpage='http://www.banki.ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_banks = pd.read_csv('closed_banks.csv', header=0, sep=',', encoding=\"cp1251\")\n",
    "closed_banks['ликвдата'] = pd.to_datetime(closed_banks['ликвдата'])\n",
    "\n",
    "# Причины по ликвидированным банкам: \n",
    "likvid_data = closed_banks[closed_banks['статус']=='ликв.']\n",
    "otozv_data = closed_banks[closed_banks['статус']=='отозв.']\n",
    "\n",
    "likvid_data.to_csv(CLOSED_BANKS_DATA_FOLDER + 'likvid_data.csv',sep='\\t',header=True,index=False)\n",
    "otozv_data.to_csv(CLOSED_BANKS_DATA_FOLDER + 'otozv_data.csv',sep='\\t',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other data was already in the form of .csv at Central Bank website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
